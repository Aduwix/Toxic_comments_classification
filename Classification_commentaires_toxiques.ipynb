{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_commentaires_toxiques.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aduwix/Toxic_comments_classification/blob/main/Classification_commentaires_toxiques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sommaire\n",
        "1. [Introduction](#introduction)\n",
        "2. [Importation des packages](#ImportPackages)\n",
        "3. [Importation des données](#ImportData)\n",
        "4. [Etude du jeu de données](#StudyData)\n",
        "5. [Préparation des données](#PrepareData)\n",
        "6. [Passage du texte dans un format structuré](#StructureData)\n",
        "7. [Entraînement du modèle baseline](#FirstModel)\n",
        "8. [Deep Learning](#DL)\n",
        "  1. [Première approche \"*from scratch*\"](#FromScratch)\n",
        "  2. [Avec une couche d'embedding déjà entrainée](#GloVe)\n",
        "  2. [LSTM bidirectionnel et Dropout](#Bidirectionnal)"
      ],
      "metadata": {
        "id": "HrF4By68oqFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction <a name=\"introduction\"></a>\n",
        "\n",
        "Dans ce notebook, nous allons tenter de classifier des commentaires dits toxiques.\n",
        "Nous allons dans un premier temps étudier notre jeu de données pour comprendre ce que nous allons traiter.\n",
        "\n",
        "Ensuite, avant de passer à la classification, il est nécessaire de préparer nos données. On s'occupe des contractions de mots, des abréviations et d'autres traitements avec notamment les stop words.\n",
        "\n",
        "L'étape suivante correspond à l'élaboration de la matrice reprenant les TFIDF pour obtenir une représentation structurée de nos données. \n",
        "\n",
        "\n",
        "## Modèle de Machine Learning classique\n",
        "\n",
        "Pour une première tentative de classification des commentaires, on part sur un algorithme de Machine Learning classique permettant de faire de la classification multi-label car un commentaire peut-être à la fois *severe_toxic* et *obscene*.\n",
        "\n",
        "On obtient alors une précision d'environ 90%.\n",
        "\n",
        "**Notre objectif est donc d'obtenir un modèle de deep learning ayant une précision du même ordre voire supérieure**\n",
        "\n",
        "## Deep Learning\n",
        "\n",
        "### From scratch\n",
        "\n",
        "Dans cette première approche, on part d'un réseau de neurones à 3 couches:\n",
        "  - Une couche d'embedding\n",
        "  - Une couche GRU de taille 64\n",
        "  - Une couche Dense de sortie\n",
        "\n",
        "### Avec une couche d'embedding déjà entrainée: GloVe\n",
        "\n",
        "Avec cette deuxième approche, on utilise une couche d'embedding déjà entrainée, GloVe."
      ],
      "metadata": {
        "id": "SCci21dcidEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation des packages <a name=\"ImportPackages\"></a>"
      ],
      "metadata": {
        "id": "_lyJzHuKRNWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "MUj96QiIQsJ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "#Réseaux de neurones\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation des données <a name=\"ImportData\"></a>"
      ],
      "metadata": {
        "id": "xZLpUMItRWc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajoutez un raccourci de ce dossier à votre google drive :\n",
        "\n",
        "https://drive.google.com/drive/folders/1mx-CAzT10YKrmxHfYDP_1Oef7PVGUr7s?usp=sharing"
      ],
      "metadata": {
        "id": "cbE3MzVKRaV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FktfCVaRVrs",
        "outputId": "5ea81dac-b8d4-4a7f-9e90-25b8b61f5071"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/data_classification_commentaires_toxiques/train.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qky64Lq8Rocy",
        "outputId": "55bc3f3f-89a3-41a9-c9da-96249c8ff3ae"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b066840f-f805-4a0f-b0ea-364ce3ca6a84\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b066840f-f805-4a0f-b0ea-364ce3ca6a84')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b066840f-f805-4a0f-b0ea-364ce3ca6a84 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b066840f-f805-4a0f-b0ea-364ce3ca6a84');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On ne prend pas la totalité du dataset pour l'entraînement pour ne pas passer trop de temps sur l'apprentissage."
      ],
      "metadata": {
        "id": "fABUqgIWwHYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(data.index)\n",
        "data = data.iloc[:30000, :]"
      ],
      "metadata": {
        "id": "RSPSuakVwFPu"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etude du jeu de données <a name=\"StudyData\"></a>"
      ],
      "metadata": {
        "id": "-kUWzBzISpsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une première étape consiste à enlever certains caractères spéciaux présents dans les commentaires."
      ],
      "metadata": {
        "id": "p0ktlV3DwnZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['comment_text'] = data['comment_text'].apply(lambda x : x.replace('\\ufeff', ''))\n",
        "data['comment_text'] = data['comment_text'].apply(lambda x : x.replace('\\xa0', ''))\n",
        "data['comment_text'] = data['comment_text'].apply(lambda x : x.replace('&#39;', ' '))"
      ],
      "metadata": {
        "id": "CAexGL7jS-VF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e9bc4d-71e4-4e1b-beaa-19f0a8bf4a37"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On veut maintenant essayer de comprendre notre jeu de données avec différentes caractéristiques, on commence par la fréquence des commentaires selon leur classe type."
      ],
      "metadata": {
        "id": "oJrkCk5nwtqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "types = [\"Normal\", \"Toxic\", \"Severe Toxic\", \"Obscene\", \"Threat\", \"Insult\", \"Identity Hate\"]\n",
        "\n",
        "#On définit nos différents labels\n",
        "labels = data.columns[2:]\n",
        "\n",
        "values = [len(data[(data['toxic'] == 0) & (data['severe_toxic'] == 0) & (data['obscene'] == 0) & (data['threat'] == 0) & (data['insult'] == 0) & (data['identity_hate'] == 0)])]\n",
        "for column in labels:\n",
        "  values.append(data[column].value_counts().to_numpy()[1])\n",
        "\n",
        "ax.bar(types,values)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "73VmTHbCwucT",
        "outputId": "3e249fea-41e5-45a1-aee6-0a52decfa1ce"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque ici que le nombre de commentaires dits \"normaux\" est bien supérieur au nombre de commentaires toxiques de tous types. On remarque aussi que certaines classes sont plus présentes que d'autres: 'toxic', 'obscene' et 'insult' ont plus d'exemples que 'severe_toxic', 'threat' et 'identity hate'."
      ],
      "metadata": {
        "id": "xS9OmFkXwyFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut aussi regarder la taille de nos commentaires"
      ],
      "metadata": {
        "id": "10HNJENAGmJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length = data['comment_text'].str.len()\n",
        "length.hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "h7rz6_wtGzTY",
        "outputId": "f7981969-2ced-4ca6-eec1-09579b088160"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque que la longueur des commentaires (en caractères) est dans la majorité des cas inférieure à 500"
      ],
      "metadata": {
        "id": "0vXSUW2YHvhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Taille Moyenne d'un commentaire (nombre de caractères): {} \".format(np.mean(data['comment_text'].str.len())))\n",
        "average_size = np.mean([len(comment.split()) for comment in data['comment_text']])\n",
        "print(\"Taille Moyenne d'un commentaire (nombre de mots): {} \".format(average_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lydp2kAJHsxZ",
        "outputId": "3750e39e-c4f6-4b85-d679-c1bf104ca636"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille Moyenne d'un commentaire (nombre de caractères): 393.14113333333336 \n",
            "Taille Moyenne d'un commentaire (nombre de mots): 67.1352 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Taille Maximale d'un commentaire (nombre de caractères): {} \".format(np.max(data['comment_text'].str.len())))\n",
        "max_size = np.max([len(comment.split()) for comment in data['comment_text']])\n",
        "print(\"Taille Maximale d'un commentaire (nombre de mots): {} \".format(max_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSs2L-fWIYtJ",
        "outputId": "7c52f200-aa54-4588-cc03-74f8240572a2"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille Maximale d'un commentaire (nombre de caractères): 5000 \n",
            "Taille Maximale d'un commentaire (nombre de mots): 1403 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Préparation des données <a name=\"PrepareData\"></a>"
      ],
      "metadata": {
        "id": "YIzpSrAjSsAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'objectif est maintenant de nettoyer le jeu de données. On va notamment essayer de remplacer les contractions et abreviations les plus courantes."
      ],
      "metadata": {
        "id": "kEVsO7quw0yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "1WMk85t8S_zX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3639b4-f008-4e23-b367-76c7e9875331"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On définit plusieurs fonctions nous permettant de nettoyer les commentaires."
      ],
      "metadata": {
        "id": "ulN4woGfw5gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(comment): \n",
        "            \n",
        "    # Contractions\n",
        "    comment = re.sub(r\"he's\", \"he is\", comment)\n",
        "    comment = re.sub(r\"there's\", \"there is\", comment)\n",
        "    comment = re.sub(r\"We're\", \"We are\", comment)\n",
        "    comment = re.sub(r\"That's\", \"That is\", comment)\n",
        "    comment = re.sub(r\"won't\", \"will not\", comment)\n",
        "    comment = re.sub(r\"they're\", \"they are\", comment)\n",
        "    comment = re.sub(r\"Can't\", \"Cannot\", comment)\n",
        "    comment = re.sub(r\"wasn't\", \"was not\", comment)\n",
        "    comment = re.sub(r\"don\\x89Ûªt\", \"do not\", comment)\n",
        "    comment = re.sub(r\"aren't\", \"are not\", comment)\n",
        "    comment = re.sub(r\"isn't\", \"is not\", comment)\n",
        "    comment = re.sub(r\"What's\", \"What is\", comment)\n",
        "    comment = re.sub(r\"haven't\", \"have not\", comment)\n",
        "    comment = re.sub(r\"hasn't\", \"has not\", comment)\n",
        "    comment = re.sub(r\"There's\", \"There is\", comment)\n",
        "    comment = re.sub(r\"He's\", \"He is\", comment)\n",
        "    comment = re.sub(r\"It's\", \"It is\", comment)\n",
        "    comment = re.sub(r\"You're\", \"You are\", comment)\n",
        "    comment = re.sub(r\"I'M\", \"I am\", comment)\n",
        "    comment = re.sub(r\"shouldn't\", \"should not\", comment)\n",
        "    comment = re.sub(r\"wouldn't\", \"would not\", comment)\n",
        "    comment = re.sub(r\"i'm\", \"I am\", comment)\n",
        "    comment = re.sub(r\"I\\x89Ûªm\", \"I am\", comment)\n",
        "    comment = re.sub(r\"I'm\", \"I am\", comment)\n",
        "    comment = re.sub(r\"Isn't\", \"is not\", comment)\n",
        "    comment = re.sub(r\"Here's\", \"Here is\", comment)\n",
        "    comment = re.sub(r\"you've\", \"you have\", comment)\n",
        "    comment = re.sub(r\"you\\x89Ûªve\", \"you have\", comment)\n",
        "    comment = re.sub(r\"we're\", \"we are\", comment)\n",
        "    comment = re.sub(r\"what's\", \"what is\", comment)\n",
        "    comment = re.sub(r\"couldn't\", \"could not\", comment)\n",
        "    comment = re.sub(r\"we've\", \"we have\", comment)\n",
        "    comment = re.sub(r\"it\\x89Ûªs\", \"it is\", comment)\n",
        "    comment = re.sub(r\"doesn\\x89Ûªt\", \"does not\", comment)\n",
        "    comment = re.sub(r\"It\\x89Ûªs\", \"It is\", comment)\n",
        "    comment = re.sub(r\"Here\\x89Ûªs\", \"Here is\", comment)\n",
        "    comment = re.sub(r\"who's\", \"who is\", comment)\n",
        "    comment = re.sub(r\"I\\x89Ûªve\", \"I have\", comment)\n",
        "    comment = re.sub(r\"y'all\", \"you all\", comment)\n",
        "    comment = re.sub(r\"can\\x89Ûªt\", \"cannot\", comment)\n",
        "    comment = re.sub(r\"would've\", \"would have\", comment)\n",
        "    comment = re.sub(r\"it'll\", \"it will\", comment)\n",
        "    comment = re.sub(r\"we'll\", \"we will\", comment)\n",
        "    comment = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", comment)\n",
        "    comment = re.sub(r\"We've\", \"We have\", comment)\n",
        "    comment = re.sub(r\"he'll\", \"he will\", comment)\n",
        "    comment = re.sub(r\"Y'all\", \"You all\", comment)\n",
        "    comment = re.sub(r\"Weren't\", \"Were not\", comment)\n",
        "    comment = re.sub(r\"Didn't\", \"Did not\", comment)\n",
        "    comment = re.sub(r\"they'll\", \"they will\", comment)\n",
        "    comment = re.sub(r\"they'd\", \"they would\", comment)\n",
        "    comment = re.sub(r\"DON'T\", \"DO NOT\", comment)\n",
        "    comment = re.sub(r\"That\\x89Ûªs\", \"That is\", comment)\n",
        "    comment = re.sub(r\"they've\", \"they have\", comment)\n",
        "    comment = re.sub(r\"i'd\", \"I would\", comment)\n",
        "    comment = re.sub(r\"should've\", \"should have\", comment)\n",
        "    comment = re.sub(r\"You\\x89Ûªre\", \"You are\", comment)\n",
        "    comment = re.sub(r\"where's\", \"where is\", comment)\n",
        "    comment = re.sub(r\"Don\\x89Ûªt\", \"Do not\", comment)\n",
        "    comment = re.sub(r\"we'd\", \"we would\", comment)\n",
        "    comment = re.sub(r\"i'll\", \"I will\", comment)\n",
        "    comment = re.sub(r\"weren't\", \"were not\", comment)\n",
        "    comment = re.sub(r\"They're\", \"They are\", comment)\n",
        "    comment = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", comment)\n",
        "    comment = re.sub(r\"you\\x89Ûªll\", \"you will\", comment)\n",
        "    comment = re.sub(r\"I\\x89Ûªd\", \"I would\", comment)\n",
        "    comment = re.sub(r\"let's\", \"let us\", comment)\n",
        "    comment = re.sub(r\"it's\", \"it is\", comment)\n",
        "    comment = re.sub(r\"can't\", \"cannot\", comment)\n",
        "    comment = re.sub(r\"don't\", \"do not\", comment)\n",
        "    comment = re.sub(r\"you're\", \"you are\", comment)\n",
        "    comment = re.sub(r\"i've\", \"I have\", comment)\n",
        "    comment = re.sub(r\"that's\", \"that is\", comment)\n",
        "    comment = re.sub(r\"i'll\", \"I will\", comment)\n",
        "    comment = re.sub(r\"doesn't\", \"does not\", comment)\n",
        "    comment = re.sub(r\"i'd\", \"I would\", comment)\n",
        "    comment = re.sub(r\"didn't\", \"did not\", comment)\n",
        "    comment = re.sub(r\"ain't\", \"am not\", comment)\n",
        "    comment = re.sub(r\"you'll\", \"you will\", comment)\n",
        "    comment = re.sub(r\"I've\", \"I have\", comment)\n",
        "    comment = re.sub(r\"Don't\", \"do not\", comment)\n",
        "    comment = re.sub(r\"I'll\", \"I will\", comment)\n",
        "    comment = re.sub(r\"I'd\", \"I would\", comment)\n",
        "    comment = re.sub(r\"Let's\", \"Let us\", comment)\n",
        "    comment = re.sub(r\"you'd\", \"You would\", comment)\n",
        "    comment = re.sub(r\"It's\", \"It is\", comment)\n",
        "    comment = re.sub(r\"Ain't\", \"am not\", comment)\n",
        "    comment = re.sub(r\"Haven't\", \"Have not\", comment)\n",
        "    comment = re.sub(r\"Could've\", \"Could have\", comment)\n",
        "    comment = re.sub(r\"youve\", \"you have\", comment)  \n",
        "    comment = re.sub(r\"donå«t\", \"do not\", comment)  \n",
        "    \n",
        "    comment = re.sub(r\"some1\", \"someone\", comment)\n",
        "    comment = re.sub(r\"yrs\", \"years\", comment)\n",
        "    comment = re.sub(r\"hrs\", \"hours\", comment)\n",
        "    comment = re.sub(r\"2morow|2moro\", \"tomorrow\", comment)\n",
        "    comment = re.sub(r\"2day\", \"today\", comment)\n",
        "    comment = re.sub(r\"4got|4gotten\", \"forget\", comment)\n",
        "    comment = re.sub(r\"b-day|bday\", \"b-day\", comment)\n",
        "    comment = re.sub(r\"mother's\", \"mother\", comment)\n",
        "    comment = re.sub(r\"mom's\", \"mom\", comment)\n",
        "    comment = re.sub(r\"dad's\", \"dad\", comment)\n",
        "    comment = re.sub(r\"hahah|hahaha|hahahaha\", \"haha\", comment)\n",
        "    comment = re.sub(r\"lmao|lolz|rofl\", \"lol\", comment)\n",
        "    comment = re.sub(r\"thanx|thnx\", \"thanks\", comment)\n",
        "    comment = re.sub(r\"goood\", \"good\", comment)\n",
        "    comment = re.sub(r\"some1\", \"someone\", comment)\n",
        "    comment = re.sub(r\"some1\", \"someone\", comment)\n",
        "    # Character entity references\n",
        "    comment = re.sub(r\"&gt;\", \">\", comment)\n",
        "    comment = re.sub(r\"&lt;\", \"<\", comment)\n",
        "    comment = re.sub(r\"&amp;\", \"&\", comment)\n",
        "    # Typos, slang and informal abbreviations\n",
        "    comment = re.sub(r\"w/e\", \"whatever\", comment)\n",
        "    comment = re.sub(r\"w/\", \"with\", comment)\n",
        "    comment = re.sub(r\"<3\", \"love\", comment)\n",
        "    # Urls\n",
        "    comment = re.sub(r\"http\\S+\", \"\", comment)\n",
        "    # Numbers\n",
        "    comment = re.sub(r'[0-9]', '', comment)\n",
        "    # Eliminating the mentions\n",
        "    comment = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", comment)\n",
        "    # Remove punctuation and special chars (keep '!')\n",
        "    for p in string.punctuation.replace('!', ''):\n",
        "        comment = comment.replace(p, '')\n",
        "        \n",
        "    # ... and ..\n",
        "    comment = comment.replace('...', ' ... ')\n",
        "    if '...' not in comment:\n",
        "        comment = comment.replace('..', ' ... ')\n",
        "        \n",
        "    # Tokenize\n",
        "    comment_words = word_tokenize(comment)\n",
        "    \n",
        "    # Eliminating the word if its length is less than 3\n",
        "    comment = [w for w in comment_words if len(w)>2]\n",
        "    \n",
        "    # remove stopwords\n",
        "    comment = [w.lower() for w in comment if not w in stop_words]  \n",
        "    \n",
        "    \n",
        "    # join back\n",
        "    comment = ' '.join(comment)\n",
        "        \n",
        "        \n",
        "    return comment"
      ],
      "metadata": {
        "id": "1ea2Vnv1w58k"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable_name = \"\"\n",
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"€\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", \n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "     \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}\n",
        "\n",
        "def convert_abbrev_in_text(comment):\n",
        "    t=[]\n",
        "    words=comment.split()\n",
        "    t = [abbreviations[w.lower()] if w.lower() in abbreviations.keys() else w for w in words]\n",
        "    return ' '.join(t) "
      ],
      "metadata": {
        "id": "zR4rjLDQw82b"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction prepare_string permet d'appliquer les deux traitements définis précédemment pour netoyer les commentaires."
      ],
      "metadata": {
        "id": "RQzYqwwxw_ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_string(comment):\n",
        "  comment = clean(comment)\n",
        "  comment = convert_abbrev_in_text(comment)\n",
        "  return comment"
      ],
      "metadata": {
        "id": "1Na_5KzcxAv7"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "data['comment_text'] = data['comment_text'].apply(lambda s : prepare_string(s))\n",
        "\n",
        "# Drop empty values from dataframe\n",
        "data['comment_text'].replace('', np.nan, inplace=True)\n",
        "data.dropna(subset=['comment_text'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKbnzpjTxB6D",
        "outputId": "ec94d4a2-07b2-476a-dc1f-57b1cbe9d5e9"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 20.5 s, sys: 61.5 ms, total: 20.6 s\n",
            "Wall time: 20.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(20)"
      ],
      "metadata": {
        "id": "DWTQi3ibxEe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "e3f07213-0c24-4efa-88f7-a08fb931857f"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  id                                       comment_text  \\\n",
              "0   0000997932d777bf  explanation why edits made username hardcore m...   \n",
              "1   000103f0d9cfb60f  daww matches background colour seemingly stuck...   \n",
              "2   000113f07ec002fd  hey man really trying edit war guy constantly ...   \n",
              "3   0001b41b1c6bb37e  more make real suggestions improvement wondere...   \n",
              "4   0001d958c54c6e35              you sir hero any chance remember page   \n",
              "5   00025465d4725e87           congratulations well use tools well talk   \n",
              "6   0002bcb3da6cb337             cocksucker before you piss around work   \n",
              "7   00031b1e95af7921  your vandalism matt shirvington article revert...   \n",
              "8   00037261f536c51d  sorry word nonsense offensive anyway intending...   \n",
              "9   00040093b2687caa               alignment subject contrary dulithgow   \n",
              "10  0005300084f90edc  fair use rationale imagewonjujpg thanks upload...   \n",
              "11  00054a5e18b50dd4                 bbq man lets discuss itmaybe phone   \n",
              "12  0005c987bdfc9d4b  hey talk what exclusive group talibanswho good...   \n",
              "13  0006f16e4e9f292e  before start throwing accusations warnings let...   \n",
              "14  00070ef96486d6f9  girl started arguments she stuck nose belong b...   \n",
              "15  00078f8ce7eb276d  juelz santanas age juelz santana years old cam...   \n",
              "16  0007e25b2121310b            bye look come think comming back tosser   \n",
              "17  000897889268bc93     redirect talkvoydan pop georgiev chernodrinski   \n",
              "18  0009801bd85e5806  the mitsurugi point made sense argue include h...   \n",
              "19  0009eaea3325de8c  mean bother see writing something regarding re...   \n",
              "\n",
              "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0       0             0        0       0       0              0  \n",
              "1       0             0        0       0       0              0  \n",
              "2       0             0        0       0       0              0  \n",
              "3       0             0        0       0       0              0  \n",
              "4       0             0        0       0       0              0  \n",
              "5       0             0        0       0       0              0  \n",
              "6       1             1        1       0       1              0  \n",
              "7       0             0        0       0       0              0  \n",
              "8       0             0        0       0       0              0  \n",
              "9       0             0        0       0       0              0  \n",
              "10      0             0        0       0       0              0  \n",
              "11      0             0        0       0       0              0  \n",
              "12      1             0        0       0       0              0  \n",
              "13      0             0        0       0       0              0  \n",
              "14      0             0        0       0       0              0  \n",
              "15      0             0        0       0       0              0  \n",
              "16      1             0        0       0       0              0  \n",
              "17      0             0        0       0       0              0  \n",
              "18      0             0        0       0       0              0  \n",
              "19      0             0        0       0       0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52636a55-98c6-494c-85d6-7d030b0e7d69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>explanation why edits made username hardcore m...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>daww matches background colour seemingly stuck...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>hey man really trying edit war guy constantly ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>more make real suggestions improvement wondere...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>you sir hero any chance remember page</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>congratulations well use tools well talk</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>cocksucker before you piss around work</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>your vandalism matt shirvington article revert...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>sorry word nonsense offensive anyway intending...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment subject contrary dulithgow</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0005300084f90edc</td>\n",
              "      <td>fair use rationale imagewonjujpg thanks upload...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>00054a5e18b50dd4</td>\n",
              "      <td>bbq man lets discuss itmaybe phone</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0005c987bdfc9d4b</td>\n",
              "      <td>hey talk what exclusive group talibanswho good...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0006f16e4e9f292e</td>\n",
              "      <td>before start throwing accusations warnings let...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>00070ef96486d6f9</td>\n",
              "      <td>girl started arguments she stuck nose belong b...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>00078f8ce7eb276d</td>\n",
              "      <td>juelz santanas age juelz santana years old cam...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0007e25b2121310b</td>\n",
              "      <td>bye look come think comming back tosser</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>000897889268bc93</td>\n",
              "      <td>redirect talkvoydan pop georgiev chernodrinski</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0009801bd85e5806</td>\n",
              "      <td>the mitsurugi point made sense argue include h...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0009eaea3325de8c</td>\n",
              "      <td>mean bother see writing something regarding re...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52636a55-98c6-494c-85d6-7d030b0e7d69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52636a55-98c6-494c-85d6-7d030b0e7d69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52636a55-98c6-494c-85d6-7d030b0e7d69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos commentaires sont maintenant nettoyés et prêts à être traités."
      ],
      "metadata": {
        "id": "StU2bgttxF-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passage du texte dans un format structuré <a name=\"StructureData\"></a>"
      ],
      "metadata": {
        "id": "-8AEuTKsSuLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_size = int(100000)\n",
        "#corpus_size = int(800)\n",
        "#On va maintenant prendre un échantillon de notre dataset car TfidfVectorizer() a besoin d'énormément de ram pour ses calculs si on prend le dataset entier\n",
        "\n",
        "sample_data = data.iloc[:corpus_size, :]\n",
        "\n",
        "comments = sample_data['comment_text']\n",
        "\n",
        "#On récupère maintenant les labels\n",
        "y = sample_data.drop(columns=[\"comment_text\", \"id\"]).values[:int(corpus_size)]\n",
        "\n",
        "\n",
        "tfIdfVectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = tfIdfVectorizer.fit_transform(comments).toarray()"
      ],
      "metadata": {
        "id": "AfiItZEITBK3"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînement du modèle baseline <a name=\"FirstModel\"></a>"
      ],
      "metadata": {
        "id": "LxNIQgESTCmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous étions à la base partis sur un modèle de RandomForestClassifier comme dans les TP.\n",
        "Nous avons donc constaté le manque de précision du modèle et fait une analyse afin d'améliorer la précision.\n",
        "Mais nous nous sommes finalement rendu compte que ce modèle ne peut sortir qu'une seule classe à la fois. Autrement dit, un commentaire classé comme 'toxic' par le modèle ne sera jamais classé 'obscene' car le modèle ne pourra pas sortir deux labels en même temps.\n",
        "Il faut donc utiliser un modèle permettant de faire de la multi-label classification.\n",
        "On utilise ici OneVsRestClassifier."
      ],
      "metadata": {
        "id": "D442ozw9lS0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"
      ],
      "metadata": {
        "id": "N8ZTeFJqkHEI"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = OneVsRestClassifier(RandomForestClassifier(n_estimators=15, random_state=1), n_jobs=-1)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "YgkPpzIzSQUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f80218-5f23-488e-a64f-42b000710a24"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=RandomForestClassifier(n_estimators=15,\n",
              "                                                     random_state=1),\n",
              "                    n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On analyse maintenant les performances de notre modèle baseline"
      ],
      "metadata": {
        "id": "aX3lCL2YxSwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On regarde tout d'abord les performances sur les données d'entraînement"
      ],
      "metadata": {
        "id": "2bfzWsNK_7EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[4], y_train[10])\n",
        "print(model.predict([X_train[4], X_train[10]]))\n",
        "\n",
        "training_predictions = model.predict(X_train)\n",
        "print(classification_report(y_train,training_predictions, zero_division = 1))   \n",
        "\n",
        "print(accuracy_score(y_train, training_predictions))"
      ],
      "metadata": {
        "id": "yyWRJAlzo-43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fb4c2b-6943-45b5-dd15-526168b94c65"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0 0 0] [0 0 0 0 0 0]\n",
            "[[1 0 1 0 0 0]\n",
            " [0 0 0 0 0 0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      2052\n",
            "           1       1.00      0.87      0.93       223\n",
            "           2       1.00      0.97      0.98      1098\n",
            "           3       1.00      0.85      0.92        74\n",
            "           4       1.00      0.97      0.98      1031\n",
            "           5       0.99      0.91      0.95       182\n",
            "\n",
            "   micro avg       1.00      0.96      0.98      4660\n",
            "   macro avg       1.00      0.92      0.96      4660\n",
            "weighted avg       1.00      0.96      0.98      4660\n",
            " samples avg       1.00      1.00      1.00      4660\n",
            "\n",
            "0.9926649202190998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On voit ici que nous avons une précision de 99% sur le jeu de données d'entraînement."
      ],
      "metadata": {
        "id": "k_VgD0w6A7dw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regardons maintenant les performances du modèle sur des données jamais rencontrées."
      ],
      "metadata": {
        "id": "_jUhEE2I__t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "print(classification_report(y_test,predictions, zero_division = 1))   \n",
        "\n",
        "accuracy0 = accuracy_score(y_test, predictions)\n",
        "print(\"accuracy: {}\".format(accuracy0))"
      ],
      "metadata": {
        "id": "86TfrwPyxSDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14a4291-f8f8-4a56-eb7f-64f6f62910a6"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.58      0.69       903\n",
            "           1       0.23      0.03      0.06        93\n",
            "           2       0.87      0.68      0.76       494\n",
            "           3       0.00      0.00      0.00        25\n",
            "           4       0.79      0.45      0.58       468\n",
            "           5       0.90      0.11      0.20        82\n",
            "\n",
            "   micro avg       0.84      0.52      0.64      2065\n",
            "   macro avg       0.61      0.31      0.38      2065\n",
            "weighted avg       0.81      0.52      0.62      2065\n",
            " samples avg       0.99      0.94      0.93      2065\n",
            "\n",
            "accuracy: 0.9085352300511225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque que nous avons une accuracy de 90%. Cela peut sembler correct mais on peut penser que, la dataset ayant en majorité des commentaires normaux, le modèle prédit qu'un commentaire est normal pour chaque type de commentaire."
      ],
      "metadata": {
        "id": "DN_K3-wXxWRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analysePredictions(predictions, y_test):\n",
        "  num_col = len(predictions[0])\n",
        "  num_rows = len(predictions)\n",
        "\n",
        "  report = []\n",
        "\n",
        "  for label in range(num_col):\n",
        "    true_positive = false_positive = true_negative = false_negative = count = 0\n",
        "    for i in range(num_rows):\n",
        "      pred = predictions[i][label]\n",
        "      answer = y_test[i][label]\n",
        "      if pred == 1:\n",
        "        if answer == 1:\n",
        "          count += 1\n",
        "          true_positive += 1\n",
        "        else:\n",
        "          false_positive += 1\n",
        "      else:\n",
        "        if answer == 0:\n",
        "          true_negative += 1\n",
        "        else:\n",
        "          count += 1\n",
        "          false_negative += 1\n",
        "    report.append({\n",
        "        'COUNT': count,\n",
        "        'TP': true_positive,\n",
        "        'FP': false_positive,\n",
        "        'TN': true_negative,\n",
        "        'FN': false_negative\n",
        "    })\n",
        "  return report"
      ],
      "metadata": {
        "id": "yt2SiDX2xYl7"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = analysePredictions(predictions, y_test)\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "  print(\n",
        "  \"\"\"\n",
        "  {}:\n",
        "      Count: {}\n",
        "      \n",
        "        -True positive: {}\n",
        "        -False positive: {}\n",
        "        -True negative: {}\n",
        "        -False negative: {} \n",
        "\n",
        "{}\n",
        "  \"\"\".format(label, report[i]['COUNT'], report[i]['TP'], report[i]['FP'], report[i]['TN'], report[i]['FN'], confusion_matrix(y_test[:, i], predictions[:,i]))#On a aussi la possibilité d'utiliser confusion_matrix pour déterminer ces valeurs\n",
        "  )"
      ],
      "metadata": {
        "id": "o0pXZ9qqyyLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76319d92-6f85-492a-9c00-0c0004f7c211"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  toxic:\n",
            "      Count: 903\n",
            "      \n",
            "        -True positive: 522\n",
            "        -False positive: 89\n",
            "        -True negative: 8006\n",
            "        -False negative: 381 \n",
            "\n",
            "[[8006   89]\n",
            " [ 381  522]]\n",
            "  \n",
            "\n",
            "  severe_toxic:\n",
            "      Count: 93\n",
            "      \n",
            "        -True positive: 3\n",
            "        -False positive: 10\n",
            "        -True negative: 8895\n",
            "        -False negative: 90 \n",
            "\n",
            "[[8895   10]\n",
            " [  90    3]]\n",
            "  \n",
            "\n",
            "  obscene:\n",
            "      Count: 494\n",
            "      \n",
            "        -True positive: 335\n",
            "        -False positive: 52\n",
            "        -True negative: 8452\n",
            "        -False negative: 159 \n",
            "\n",
            "[[8452   52]\n",
            " [ 159  335]]\n",
            "  \n",
            "\n",
            "  threat:\n",
            "      Count: 25\n",
            "      \n",
            "        -True positive: 0\n",
            "        -False positive: 1\n",
            "        -True negative: 8972\n",
            "        -False negative: 25 \n",
            "\n",
            "[[8972    1]\n",
            " [  25    0]]\n",
            "  \n",
            "\n",
            "  insult:\n",
            "      Count: 468\n",
            "      \n",
            "        -True positive: 212\n",
            "        -False positive: 55\n",
            "        -True negative: 8475\n",
            "        -False negative: 256 \n",
            "\n",
            "[[8475   55]\n",
            " [ 256  212]]\n",
            "  \n",
            "\n",
            "  identity_hate:\n",
            "      Count: 82\n",
            "      \n",
            "        -True positive: 9\n",
            "        -False positive: 1\n",
            "        -True negative: 8915\n",
            "        -False negative: 73 \n",
            "\n",
            "[[8915    1]\n",
            " [  73    9]]\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En analysant ces indicateurs, on se rend alors compte qu'en réalité, le modèle n'arrive pas à bien classer les commentaires toxiques en général, ceux qu'il n'a jamais rencontré.\n",
        "On voit notamment que nous avons beaucoup de faux négatifs.\n",
        "La méthode utilisant le tfidf ne semble pas être réellement performante pour de nouvelles données.\n",
        "En effet, le modèle ne semble pas être capable de généraliser."
      ],
      "metadata": {
        "id": "_LV5xeI7754P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning <a name=\"DL\"></a>"
      ],
      "metadata": {
        "id": "dUoUF1XVuVMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Première approche \"*from scratch*\" <a name=\"FromScratch\"></a>"
      ],
      "metadata": {
        "id": "2a8IWbTFTHXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons maintenant tenter d'améliorer les performances de notre modèle en passant par un réseau de neurones.\n",
        "\n",
        "Nous avons pour objectif d'obtenir une précision d'au moins 90%."
      ],
      "metadata": {
        "id": "K8XHIfOnCO_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparamètres"
      ],
      "metadata": {
        "id": "pzjEU3y9CmS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100    # Dimensions used for glove6b100\n",
        "max_length = 70        # Maximum size of a comment\n",
        "truncating='post'      # Truncates the comment if it is longer than max_length\n",
        "padding='post'    # Adds padding to the end of the comment if it is shorter than max_length\n",
        "oov_token = \"<OOV>\"      # Token \"<OOV>\" replaces words that are not part of the vocabulary (Out Of Vocabulary)\n",
        "training_size=len(data)\n",
        "test_portion=.25"
      ],
      "metadata": {
        "id": "rVR0eCkoTQSI"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/data_classification_commentaires_toxiques/train.csv')\n",
        "data = data.iloc[:50000, :]"
      ],
      "metadata": {
        "id": "sKUbv1u4zU-V"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "data['comment_text'] = data['comment_text'].apply(lambda s : prepare_string(s))\n",
        "\n",
        "# Drop empty values from dataframe\n",
        "data['comment_text'].replace('', np.nan, inplace=True)\n",
        "data.dropna(subset=['comment_text'], inplace=True)"
      ],
      "metadata": {
        "id": "epx8uQYbzIUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af1ef69-fb76-4454-8ee5-9871777b5a2f"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 34.6 s, sys: 129 ms, total: 34.7 s\n",
            "Wall time: 34.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(data[\"comment_text\"])"
      ],
      "metadata": {
        "id": "Qca8GmCNJMl5"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a maintenant un vecteur de mapping avec nos mots de notre vocabulaire"
      ],
      "metadata": {
        "id": "XqoaKJabJf6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "WmGYM4wDJj-6"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "RVn--yvgMzZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fcad9d-8886-4986-e7a2-541dc420ed1d"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(data[\"comment_text\"])\n",
        "x = pad_sequences(sequences, truncating=truncating, padding=padding, maxlen=max_length)\n",
        "#x = np.asarray(x).astype(np.float32)"
      ],
      "metadata": {
        "id": "xSVFYxX7KCR4"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[0]"
      ],
      "metadata": {
        "id": "N_68MFukKJIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07013693-d5a7-4465-f92a-d7eb46590c85"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[555,\n",
              " 127,\n",
              " 49,\n",
              " 50,\n",
              " 508,\n",
              " 4795,\n",
              " 10274,\n",
              " 671,\n",
              " 214,\n",
              " 218,\n",
              " 8921,\n",
              " 5611,\n",
              " 2351,\n",
              " 2701,\n",
              " 40,\n",
              " 941,\n",
              " 12404,\n",
              " 2433,\n",
              " 23,\n",
              " 9,\n",
              " 149,\n",
              " 332,\n",
              " 8,\n",
              " 4,\n",
              " 59,\n",
              " 3498]"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialisation du modèle"
      ],
      "metadata": {
        "id": "KYrKBi1MNBqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons dans un premier temps créer un modèle à partir de rien."
      ],
      "metadata": {
        "id": "DoRUCu_4NH4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(123)\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, input_length=max_length),\n",
        "     tf.keras.layers.GRU(64),\n",
        "     tf.keras.layers.Dense(len(labels), activation='sigmoid')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.005),metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sPmMJ-_hKMPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "858ff2b3-3a52-4c9b-c658-37e2c88060b5"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 70, 100)           10394900  \n",
            "                                                                 \n",
            " gru_10 (GRU)                (None, 64)                31872     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,427,162\n",
            "Trainable params: 10,427,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a notre modèle. Il faut maintenant l'entraîner."
      ],
      "metadata": {
        "id": "xWVZpUVgP0df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30"
      ],
      "metadata": {
        "id": "6Z691LquQYIa"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On définit nos ensembles d'entraînement et de test."
      ],
      "metadata": {
        "id": "EVDBzzvYQxTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data.drop(columns=[\"comment_text\", \"id\"]).values[:len(x)]\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_portion)"
      ],
      "metadata": {
        "id": "4E4KaGebQYsM"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On entraîne le modèle."
      ],
      "metadata": {
        "id": "9aKfBH9cRbLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(np.array(X_train), np.array(y_train), batch_size=256, epochs = num_epochs, validation_data = (np.array(X_test), np.array(y_test)) ,verbose=1)\n",
        "print(\"Training Complete\")"
      ],
      "metadata": {
        "id": "WocmfnvURdJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e0c1c28-2e59-40be-b111-262c358595cf"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "147/147 [==============================] - 7s 30ms/step - loss: 0.1580 - accuracy: 0.9259 - val_loss: 0.1170 - val_accuracy: 0.9868\n",
            "Epoch 2/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0666 - accuracy: 0.9782 - val_loss: 0.0565 - val_accuracy: 0.9951\n",
            "Epoch 3/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0410 - accuracy: 0.9459 - val_loss: 0.0556 - val_accuracy: 0.9690\n",
            "Epoch 4/30\n",
            "147/147 [==============================] - 4s 25ms/step - loss: 0.0304 - accuracy: 0.9420 - val_loss: 0.0609 - val_accuracy: 0.9359\n",
            "Epoch 5/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0243 - accuracy: 0.9084 - val_loss: 0.0663 - val_accuracy: 0.9085\n",
            "Epoch 6/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0194 - accuracy: 0.8391 - val_loss: 0.0736 - val_accuracy: 0.8580\n",
            "Epoch 7/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0149 - accuracy: 0.7428 - val_loss: 0.0772 - val_accuracy: 0.6383\n",
            "Epoch 8/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0109 - accuracy: 0.5013 - val_loss: 0.0852 - val_accuracy: 0.7420\n",
            "Epoch 9/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0080 - accuracy: 0.5758 - val_loss: 0.0960 - val_accuracy: 0.6775\n",
            "Epoch 10/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0062 - accuracy: 0.5006 - val_loss: 0.0977 - val_accuracy: 0.5721\n",
            "Epoch 11/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0046 - accuracy: 0.6253 - val_loss: 0.1063 - val_accuracy: 0.5173\n",
            "Epoch 12/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0036 - accuracy: 0.4730 - val_loss: 0.1106 - val_accuracy: 0.4419\n",
            "Epoch 13/30\n",
            "147/147 [==============================] - 4s 25ms/step - loss: 0.0028 - accuracy: 0.4365 - val_loss: 0.1178 - val_accuracy: 0.5587\n",
            "Epoch 14/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0023 - accuracy: 0.3275 - val_loss: 0.1191 - val_accuracy: 0.4374\n",
            "Epoch 15/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0018 - accuracy: 0.3840 - val_loss: 0.1259 - val_accuracy: 0.3831\n",
            "Epoch 16/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0018 - accuracy: 0.3566 - val_loss: 0.1244 - val_accuracy: 0.3889\n",
            "Epoch 17/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0017 - accuracy: 0.3608 - val_loss: 0.1335 - val_accuracy: 0.4942\n",
            "Epoch 18/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0015 - accuracy: 0.4162 - val_loss: 0.1358 - val_accuracy: 0.3773\n",
            "Epoch 19/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0015 - accuracy: 0.4591 - val_loss: 0.1347 - val_accuracy: 0.5294\n",
            "Epoch 20/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0014 - accuracy: 0.5373 - val_loss: 0.1353 - val_accuracy: 0.6008\n",
            "Epoch 21/30\n",
            "147/147 [==============================] - 4s 25ms/step - loss: 0.0013 - accuracy: 0.3992 - val_loss: 0.1429 - val_accuracy: 0.5302\n",
            "Epoch 22/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0013 - accuracy: 0.5497 - val_loss: 0.1367 - val_accuracy: 0.6039\n",
            "Epoch 23/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0013 - accuracy: 0.4803 - val_loss: 0.1443 - val_accuracy: 0.5721\n",
            "Epoch 24/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0011 - accuracy: 0.4624 - val_loss: 0.1510 - val_accuracy: 0.3708\n",
            "Epoch 25/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 8.9541e-04 - accuracy: 0.4008 - val_loss: 0.1526 - val_accuracy: 0.4352\n",
            "Epoch 26/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0011 - accuracy: 0.4414 - val_loss: 0.1471 - val_accuracy: 0.5657\n",
            "Epoch 27/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0014 - accuracy: 0.6012 - val_loss: 0.1560 - val_accuracy: 0.3985\n",
            "Epoch 28/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0013 - accuracy: 0.5365 - val_loss: 0.1555 - val_accuracy: 0.5724\n",
            "Epoch 29/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 0.0014 - accuracy: 0.5064 - val_loss: 0.1543 - val_accuracy: 0.4204\n",
            "Epoch 30/30\n",
            "147/147 [==============================] - 4s 26ms/step - loss: 9.4257e-04 - accuracy: 0.3934 - val_loss: 0.1599 - val_accuracy: 0.4387\n",
            "Training Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions = (predictions >= .5)\n",
        "accuracy1 = accuracy_score(y_test, predictions)\n",
        "print(\"accuracy: {}\".format(accuracy1))\n",
        "\n",
        "report = analysePredictions(predictions, y_test)\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "  print(\n",
        "  \"\"\"\n",
        "{}:\n",
        "    Count: {}\n",
        "      \n",
        "      -True positive: {}\n",
        "      -False positive: {}\n",
        "      -True negative: {}\n",
        "      -False negative: {} \n",
        "\n",
        "{}\n",
        "  \"\"\".format(label, report[i]['COUNT'], report[i]['TP'], report[i]['FP'], report[i]['TN'], report[i]['FN'], confusion_matrix(y_test[:, i], predictions[:,i]))#On a aussi la possibilité d'utiliser confusion_matrix pour déterminer ces valeurs\n",
        "  )"
      ],
      "metadata": {
        "id": "_hx_8HZ7tWpn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f3cc04-1e34-4db3-f23a-d15d13769dce"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8947747459390254\n",
            "\n",
            "toxic:\n",
            "    Count: 1234\n",
            "      \n",
            "      -True positive: 802\n",
            "      -False positive: 326\n",
            "      -True negative: 10937\n",
            "      -False negative: 432 \n",
            "\n",
            "[[10937   326]\n",
            " [  432   802]]\n",
            "  \n",
            "\n",
            "severe_toxic:\n",
            "    Count: 130\n",
            "      \n",
            "      -True positive: 44\n",
            "      -False positive: 50\n",
            "      -True negative: 12317\n",
            "      -False negative: 86 \n",
            "\n",
            "[[12317    50]\n",
            " [   86    44]]\n",
            "  \n",
            "\n",
            "obscene:\n",
            "    Count: 637\n",
            "      \n",
            "      -True positive: 459\n",
            "      -False positive: 145\n",
            "      -True negative: 11715\n",
            "      -False negative: 178 \n",
            "\n",
            "[[11715   145]\n",
            " [  178   459]]\n",
            "  \n",
            "\n",
            "threat:\n",
            "    Count: 44\n",
            "      \n",
            "      -True positive: 10\n",
            "      -False positive: 20\n",
            "      -True negative: 12433\n",
            "      -False negative: 34 \n",
            "\n",
            "[[12433    20]\n",
            " [   34    10]]\n",
            "  \n",
            "\n",
            "insult:\n",
            "    Count: 617\n",
            "      \n",
            "      -True positive: 328\n",
            "      -False positive: 137\n",
            "      -True negative: 11743\n",
            "      -False negative: 289 \n",
            "\n",
            "[[11743   137]\n",
            " [  289   328]]\n",
            "  \n",
            "\n",
            "identity_hate:\n",
            "    Count: 108\n",
            "      \n",
            "      -True positive: 39\n",
            "      -False positive: 34\n",
            "      -True negative: 12355\n",
            "      -False negative: 69 \n",
            "\n",
            "[[12355    34]\n",
            " [   69    39]]\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque ici que notre modèle basé sur un réseau de neurones avec une couche d'embeddings, une couche LSTM et une simple couche dense de sortie nous permet d'avoir une précision de l'ordre de 90%, comme un modèle de machine learning classique.\n",
        "On voit aussi que nous avons encore un grand nombre de faux négatifs sur les classes peu représentées."
      ],
      "metadata": {
        "id": "s6GhNBX6iLNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voici ci-dessous une fonction de permettant de classifier un ou plusieurs commentaires"
      ],
      "metadata": {
        "id": "KM2ryw93mW1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyseComments(comments):\n",
        "  if isinstance(comments, str): #La fonction peut prendre en paramètre une simple string \n",
        "    comments = [comments]\n",
        "  sequences = tokenizer.texts_to_sequences(comments)\n",
        "  x = pad_sequences(sequences, truncating=truncating, padding=padding, maxlen=max_length)\n",
        "\n",
        "  predictions = model.predict(x)\n",
        "  predictions = (predictions >= .5)\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for i, pred in enumerate(predictions):\n",
        "    tmp = []\n",
        "    for j, label in enumerate(labels):\n",
        "      if pred[j]:\n",
        "        tmp.append(label)\n",
        "    \n",
        "    if not tmp: #Si aucun label n'est choisi, alors le commentaire est normal\n",
        "      tmp.append('normal')\n",
        "\n",
        "    result.append(tmp)\n",
        "  \n",
        "  return result"
      ],
      "metadata": {
        "id": "EMotP-iCiJZA"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un exemple d'utilisation de cette fonction"
      ],
      "metadata": {
        "id": "pSv3096ZsI5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments = [\"cocksucker before you piss around work\", \"bad video bitch\", \"cool video dude i love you\"]\n",
        "result = analyseComments(comments)\n",
        "\n",
        "for i, comment in enumerate(comments):\n",
        "  print(\"'{}':\".format(comment))\n",
        "  for res in result[i]:\n",
        "    print(\"\\t-{}\".format(res))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "2OvvnAjtr8wT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e23207-c5b7-4efb-cf4a-b015bce16e80"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'cocksucker before you piss around work':\n",
            "\t-toxic\n",
            "\t-severe_toxic\n",
            "\t-obscene\n",
            "\t-insult\n",
            "\n",
            "\n",
            "'bad video bitch':\n",
            "\t-toxic\n",
            "\t-obscene\n",
            "\n",
            "\n",
            "'cool video dude i love you':\n",
            "\t-normal\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut aussi traiter un seul commentaire."
      ],
      "metadata": {
        "id": "wuuqBpYktJiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyseComments(\"cocksucker before you piss around work\")[0]"
      ],
      "metadata": {
        "id": "a0SWX0CLtOHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164e1e8f-b028-483d-d1a3-bc37515b11ee"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toxic', 'severe_toxic', 'obscene', 'insult']"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avec une couche d'embedding déjà entrainée <a name=\"GloVe\"></a>"
      ],
      "metadata": {
        "id": "xjHb2RD5wGcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons maintenant essayer d'améliorer notre modèle précédent à l'aide d'une couche d'embedding déjà entraînée"
      ],
      "metadata": {
        "id": "nU_1KuFNwJxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {};\n",
        "\n",
        "with open('/content/drive/MyDrive/RNN_sentiment_dataset/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "metadata": {
        "id": "fHTifX4nwSLC"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialisation du modèle"
      ],
      "metadata": {
        "id": "yaQ4Q3F0wmc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(123)\n",
        "model_emb = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False),\n",
        "     tf.keras.layers.GRU(64),\n",
        "     tf.keras.layers.Dense(len(labels), activation='sigmoid')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Zk1Lw0QjwmJS"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilation du modèle"
      ],
      "metadata": {
        "id": "bK6avdILw19W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_emb.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.005),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ItTawUlIwsJK"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_emb.summary()"
      ],
      "metadata": {
        "id": "XvnsXl-nw99d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd01a94-e3a2-4c26-a2eb-637418f84ae1"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 70, 100)           10394900  \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 64)                31872     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,427,162\n",
            "Trainable params: 32,262\n",
            "Non-trainable params: 10,394,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entraînement du modèle"
      ],
      "metadata": {
        "id": "Kh4VAMelxDZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_emb.fit(np.array(X_train), np.array(y_train), batch_size=256, epochs = num_epochs, validation_data = (np.array(X_test), np.array(y_test)) ,verbose=1)\n",
        "  \n",
        "print(\"Training Complete\")"
      ],
      "metadata": {
        "id": "GiTsHyxAxE7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1ce571-f8ab-49aa-8e28-e320a5237524"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "147/147 [==============================] - 6s 28ms/step - loss: 0.1203 - accuracy: 0.8640 - val_loss: 0.0612 - val_accuracy: 0.9952\n",
            "Epoch 2/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0581 - accuracy: 0.9843 - val_loss: 0.0552 - val_accuracy: 0.9925\n",
            "Epoch 3/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0525 - accuracy: 0.9599 - val_loss: 0.0533 - val_accuracy: 0.9850\n",
            "Epoch 4/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0483 - accuracy: 0.9702 - val_loss: 0.0526 - val_accuracy: 0.9742\n",
            "Epoch 5/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0451 - accuracy: 0.9671 - val_loss: 0.0525 - val_accuracy: 0.8851\n",
            "Epoch 6/30\n",
            "147/147 [==============================] - 4s 24ms/step - loss: 0.0417 - accuracy: 0.9530 - val_loss: 0.0554 - val_accuracy: 0.9731\n",
            "Epoch 7/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0386 - accuracy: 0.9614 - val_loss: 0.0544 - val_accuracy: 0.9634\n",
            "Epoch 8/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0359 - accuracy: 0.9558 - val_loss: 0.0565 - val_accuracy: 0.8841\n",
            "Epoch 9/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0354 - accuracy: 0.9060 - val_loss: 0.0560 - val_accuracy: 0.9774\n",
            "Epoch 10/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0314 - accuracy: 0.9559 - val_loss: 0.0622 - val_accuracy: 0.9422\n",
            "Epoch 11/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0286 - accuracy: 0.9323 - val_loss: 0.0618 - val_accuracy: 0.9044\n",
            "Epoch 12/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0264 - accuracy: 0.9238 - val_loss: 0.0667 - val_accuracy: 0.8825\n",
            "Epoch 13/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0251 - accuracy: 0.8743 - val_loss: 0.0684 - val_accuracy: 0.8807\n",
            "Epoch 14/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0230 - accuracy: 0.8662 - val_loss: 0.0738 - val_accuracy: 0.8511\n",
            "Epoch 15/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0215 - accuracy: 0.8575 - val_loss: 0.0743 - val_accuracy: 0.8909\n",
            "Epoch 16/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0203 - accuracy: 0.8253 - val_loss: 0.0766 - val_accuracy: 0.9229\n",
            "Epoch 17/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0192 - accuracy: 0.8329 - val_loss: 0.0830 - val_accuracy: 0.6644\n",
            "Epoch 18/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0176 - accuracy: 0.7462 - val_loss: 0.0826 - val_accuracy: 0.6485\n",
            "Epoch 19/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0165 - accuracy: 0.7543 - val_loss: 0.0843 - val_accuracy: 0.7156\n",
            "Epoch 20/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0159 - accuracy: 0.6854 - val_loss: 0.0882 - val_accuracy: 0.6981\n",
            "Epoch 21/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0155 - accuracy: 0.7364 - val_loss: 0.0904 - val_accuracy: 0.7822\n",
            "Epoch 22/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0138 - accuracy: 0.6536 - val_loss: 0.0956 - val_accuracy: 0.6186\n",
            "Epoch 23/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0124 - accuracy: 0.6480 - val_loss: 0.0951 - val_accuracy: 0.6366\n",
            "Epoch 24/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0124 - accuracy: 0.6382 - val_loss: 0.0996 - val_accuracy: 0.5606\n",
            "Epoch 25/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0125 - accuracy: 0.6404 - val_loss: 0.0985 - val_accuracy: 0.6117\n",
            "Epoch 26/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0118 - accuracy: 0.6551 - val_loss: 0.1006 - val_accuracy: 0.6771\n",
            "Epoch 27/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0106 - accuracy: 0.6843 - val_loss: 0.1078 - val_accuracy: 0.7219\n",
            "Epoch 28/30\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.0096 - accuracy: 0.6227 - val_loss: 0.1096 - val_accuracy: 0.5612\n",
            "Epoch 29/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0095 - accuracy: 0.6076 - val_loss: 0.1124 - val_accuracy: 0.5934\n",
            "Epoch 30/30\n",
            "147/147 [==============================] - 3s 24ms/step - loss: 0.0095 - accuracy: 0.6124 - val_loss: 0.1149 - val_accuracy: 0.6794\n",
            "Training Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_emb.predict(X_test)\n",
        "predictions = (predictions >= .5)\n",
        "accuracy2 = accuracy_score(y_test, predictions)\n",
        "print(\"accuracy: {}\".format(accuracy2))\n",
        "\n",
        "report = analysePredictions(predictions, y_test)\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "  print(\n",
        "  \"\"\"\n",
        "{}:\n",
        "    Count: {}\n",
        "      \n",
        "      -True positive: {}\n",
        "      -False positive: {}\n",
        "      -True negative: {}\n",
        "      -False negative: {} \n",
        "\n",
        "{}\n",
        "  \"\"\".format(label, report[i]['COUNT'], report[i]['TP'], report[i]['FP'], report[i]['TN'], report[i]['FN'], confusion_matrix(y_test[:, i], predictions[:,i]))#On a aussi la possibilité d'utiliser confusion_matrix pour déterminer ces valeurs\n",
        "  )"
      ],
      "metadata": {
        "id": "mzap8CtvxFwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde79401-5468-4734-d73b-a76e50ff159a"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9012563015123629\n",
            "\n",
            "toxic:\n",
            "    Count: 1234\n",
            "      \n",
            "      -True positive: 872\n",
            "      -False positive: 287\n",
            "      -True negative: 10976\n",
            "      -False negative: 362 \n",
            "\n",
            "[[10976   287]\n",
            " [  362   872]]\n",
            "  \n",
            "\n",
            "severe_toxic:\n",
            "    Count: 130\n",
            "      \n",
            "      -True positive: 32\n",
            "      -False positive: 33\n",
            "      -True negative: 12334\n",
            "      -False negative: 98 \n",
            "\n",
            "[[12334    33]\n",
            " [   98    32]]\n",
            "  \n",
            "\n",
            "obscene:\n",
            "    Count: 637\n",
            "      \n",
            "      -True positive: 437\n",
            "      -False positive: 120\n",
            "      -True negative: 11740\n",
            "      -False negative: 200 \n",
            "\n",
            "[[11740   120]\n",
            " [  200   437]]\n",
            "  \n",
            "\n",
            "threat:\n",
            "    Count: 44\n",
            "      \n",
            "      -True positive: 5\n",
            "      -False positive: 13\n",
            "      -True negative: 12440\n",
            "      -False negative: 39 \n",
            "\n",
            "[[12440    13]\n",
            " [   39     5]]\n",
            "  \n",
            "\n",
            "insult:\n",
            "    Count: 617\n",
            "      \n",
            "      -True positive: 312\n",
            "      -False positive: 124\n",
            "      -True negative: 11756\n",
            "      -False negative: 305 \n",
            "\n",
            "[[11756   124]\n",
            " [  305   312]]\n",
            "  \n",
            "\n",
            "identity_hate:\n",
            "    Count: 108\n",
            "      \n",
            "      -True positive: 38\n",
            "      -False positive: 34\n",
            "      -True negative: 12355\n",
            "      -False negative: 70 \n",
            "\n",
            "[[12355    34]\n",
            " [   70    38]]\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy du modèle baseline: {}\".format(accuracy0))\n",
        "print(\"Accuracy du modèle DL from scratch: {}\".format(accuracy1))\n",
        "print(\"Accuracy du modèle DL avec couche d'embedding entrainée: {}\".format(accuracy2))"
      ],
      "metadata": {
        "id": "vytuPlAuwJEB",
        "outputId": "b17e3ad9-d4cc-4bad-f374-639e21ccd491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy du modèle baseline: 0.9085352300511225\n",
            "Accuracy du modèle DL from scratch: 0.8947747459390254\n",
            "Accuracy du modèle DL avec couche d'embedding entrainée: 0.9012563015123629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque que l'ajout d'une couche d'embedding déjà entrainée de permet pas d'obtenir une meilleure précision. \n",
        "On peut donc garder notre premier modèle de Deep Learning sans problème."
      ],
      "metadata": {
        "id": "lQu5lxBKEy2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyseComments_emb(comments):\n",
        "  if isinstance(comments, str): #La fonction peut prendre en paramètre une simple string \n",
        "    comments = [comments]\n",
        "  sequences = tokenizer.texts_to_sequences(comments)\n",
        "  x = pad_sequences(sequences, truncating=truncating, padding=padding, maxlen=max_length)\n",
        "\n",
        "  predictions = model_emb.predict(x)\n",
        "  predictions = (predictions >= .5)\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for i, pred in enumerate(predictions):\n",
        "    tmp = []\n",
        "    for j, label in enumerate(labels):\n",
        "      if pred[j]:\n",
        "        tmp.append(label)\n",
        "    \n",
        "    if not tmp: #Si aucun label n'est choisi, alors le commentaire est normal\n",
        "      tmp.append('normal')\n",
        "\n",
        "    result.append(tmp)\n",
        "  \n",
        "  return result"
      ],
      "metadata": {
        "id": "e43EVapVSvbd"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments = [\"the accuracy of our model is only 90%\", \"this model is shit\", \"This model is really great!\"]\n",
        "result = analyseComments(comments)\n",
        "\n",
        "for i, comment in enumerate(comments):\n",
        "  print(\"'{}':\".format(comment))\n",
        "  for res in result[i]:\n",
        "    print(\"\\t-{}\".format(res))\n",
        "  print(\"\\n\")\n",
        "\n",
        "print(\"Model with embedding trained\")\n",
        "#Avec le deuxième modèle avec une couche d'embedding entrainée\n",
        "result = analyseComments_emb(comments)\n",
        "\n",
        "for i, comment in enumerate(comments):\n",
        "  print(\"'{}':\".format(comment))\n",
        "  for res in result[i]:\n",
        "    print(\"\\t-{}\".format(res))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuY_UfYcFDtT",
        "outputId": "2cc170eb-a47c-494f-998a-297f3313242f"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'the accuracy of our model is only 90%':\n",
            "\t-normal\n",
            "\n",
            "\n",
            "'this model is shit':\n",
            "\t-toxic\n",
            "\t-obscene\n",
            "\t-insult\n",
            "\n",
            "\n",
            "'This model is really great!':\n",
            "\t-normal\n",
            "\n",
            "\n",
            "Model with embedding trained\n",
            "'the accuracy of our model is only 90%':\n",
            "\t-normal\n",
            "\n",
            "\n",
            "'this model is shit':\n",
            "\t-toxic\n",
            "\t-obscene\n",
            "\n",
            "\n",
            "'This model is really great!':\n",
            "\t-normal\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ci-dessous une tentative d'amélioration du modèle."
      ],
      "metadata": {
        "id": "_X-bMQgROjUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Bidirectionnel et dropout <a name=\"Bidirectionnal\">"
      ],
      "metadata": {
        "id": "nBBiPXWNxf7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On essaye ici d'améliorer le modèle en le rendant moins susceptible à l'overfit grâce au dropout.\n",
        "On utilise aussi une couche LSTM bidirectionnelle pour essayer d'avoir une meilleure compréhension des commentaires en ayant aussi des informations futures."
      ],
      "metadata": {
        "id": "vv_-amwxXH2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_drop = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False),\n",
        "     tf.keras.layers.Dropout(.4),\n",
        "     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "     tf.keras.layers.Dense(len(labels), activation='sigmoid')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_drop.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "k1ne0o3Lydev"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_drop.summary()"
      ],
      "metadata": {
        "id": "t9lCFJXMy_UN",
        "outputId": "5818cbf1-a686-4b18-d60f-92dd20e2028c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 70, 100)           10394900  \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 70, 100)           0         \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, 256)              234496    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,630,938\n",
            "Trainable params: 236,038\n",
            "Non-trainable params: 10,394,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_drop.fit(np.array(X_train), np.array(y_train), batch_size=256, epochs = 60, validation_data = (np.array(X_test), np.array(y_test)) ,verbose=1)\n",
        "  \n",
        "print(\"Training Complete\")"
      ],
      "metadata": {
        "id": "nhDixAQwzC6k",
        "outputId": "af4985c2-5bfb-4663-860f-388ddb0cc92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "147/147 [==============================] - 13s 67ms/step - loss: 0.1277 - accuracy: 0.9413 - val_loss: 0.0771 - val_accuracy: 0.9946\n",
            "Epoch 2/60\n",
            "147/147 [==============================] - 7s 51ms/step - loss: 0.0755 - accuracy: 0.9909 - val_loss: 0.0672 - val_accuracy: 0.9952\n",
            "Epoch 3/60\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 0.0690 - accuracy: 0.9844 - val_loss: 0.0631 - val_accuracy: 0.9946\n",
            "Epoch 4/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0651 - accuracy: 0.9882 - val_loss: 0.0606 - val_accuracy: 0.9880\n",
            "Epoch 5/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0629 - accuracy: 0.9900 - val_loss: 0.0579 - val_accuracy: 0.9886\n",
            "Epoch 6/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0616 - accuracy: 0.9837 - val_loss: 0.0570 - val_accuracy: 0.9948\n",
            "Epoch 7/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0593 - accuracy: 0.9875 - val_loss: 0.0585 - val_accuracy: 0.9924\n",
            "Epoch 8/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0581 - accuracy: 0.9781 - val_loss: 0.0560 - val_accuracy: 0.9893\n",
            "Epoch 9/60\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 0.0563 - accuracy: 0.9801 - val_loss: 0.0546 - val_accuracy: 0.9920\n",
            "Epoch 10/60\n",
            "147/147 [==============================] - 9s 58ms/step - loss: 0.0554 - accuracy: 0.9513 - val_loss: 0.0538 - val_accuracy: 0.9930\n",
            "Epoch 11/60\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 0.0537 - accuracy: 0.9557 - val_loss: 0.0532 - val_accuracy: 0.9928\n",
            "Epoch 12/60\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 0.0531 - accuracy: 0.9700 - val_loss: 0.0540 - val_accuracy: 0.9702\n",
            "Epoch 13/60\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 0.0520 - accuracy: 0.9693 - val_loss: 0.0527 - val_accuracy: 0.9674\n",
            "Epoch 14/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0507 - accuracy: 0.9586 - val_loss: 0.0544 - val_accuracy: 0.9097\n",
            "Epoch 15/60\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 0.0502 - accuracy: 0.9680 - val_loss: 0.0522 - val_accuracy: 0.9695\n",
            "Epoch 16/60\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 0.0494 - accuracy: 0.9595 - val_loss: 0.0524 - val_accuracy: 0.9569\n",
            "Epoch 17/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0484 - accuracy: 0.9617 - val_loss: 0.0533 - val_accuracy: 0.9752\n",
            "Epoch 18/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0470 - accuracy: 0.9365 - val_loss: 0.0548 - val_accuracy: 0.7539\n",
            "Epoch 19/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0465 - accuracy: 0.9315 - val_loss: 0.0525 - val_accuracy: 0.9554\n",
            "Epoch 20/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0452 - accuracy: 0.9325 - val_loss: 0.0522 - val_accuracy: 0.9719\n",
            "Epoch 21/60\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 0.0452 - accuracy: 0.9377 - val_loss: 0.0535 - val_accuracy: 0.9144\n",
            "Epoch 22/60\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 0.0437 - accuracy: 0.9416 - val_loss: 0.0539 - val_accuracy: 0.8885\n",
            "Epoch 23/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0429 - accuracy: 0.9271 - val_loss: 0.0531 - val_accuracy: 0.9528\n",
            "Epoch 24/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0427 - accuracy: 0.9272 - val_loss: 0.0535 - val_accuracy: 0.9648\n",
            "Epoch 25/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0416 - accuracy: 0.9129 - val_loss: 0.0540 - val_accuracy: 0.9183\n",
            "Epoch 26/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0406 - accuracy: 0.9329 - val_loss: 0.0530 - val_accuracy: 0.9431\n",
            "Epoch 27/60\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 0.0435 - accuracy: 0.9138 - val_loss: 0.0541 - val_accuracy: 0.9266\n",
            "Epoch 28/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0413 - accuracy: 0.9270 - val_loss: 0.0529 - val_accuracy: 0.9630\n",
            "Epoch 29/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0401 - accuracy: 0.9261 - val_loss: 0.0541 - val_accuracy: 0.8585\n",
            "Epoch 30/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0392 - accuracy: 0.8933 - val_loss: 0.0537 - val_accuracy: 0.9312\n",
            "Epoch 31/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0383 - accuracy: 0.9037 - val_loss: 0.0545 - val_accuracy: 0.8466\n",
            "Epoch 32/60\n",
            "147/147 [==============================] - 8s 55ms/step - loss: 0.0371 - accuracy: 0.9039 - val_loss: 0.0556 - val_accuracy: 0.9181\n",
            "Epoch 33/60\n",
            "147/147 [==============================] - 8s 52ms/step - loss: 0.0368 - accuracy: 0.8898 - val_loss: 0.0556 - val_accuracy: 0.8937\n",
            "Epoch 34/60\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 0.0357 - accuracy: 0.8875 - val_loss: 0.0567 - val_accuracy: 0.7099\n",
            "Epoch 35/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0357 - accuracy: 0.8498 - val_loss: 0.0577 - val_accuracy: 0.8693\n",
            "Epoch 36/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0345 - accuracy: 0.8563 - val_loss: 0.0579 - val_accuracy: 0.8352\n",
            "Epoch 37/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0344 - accuracy: 0.8391 - val_loss: 0.0577 - val_accuracy: 0.7617\n",
            "Epoch 38/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0338 - accuracy: 0.8330 - val_loss: 0.0581 - val_accuracy: 0.7396\n",
            "Epoch 39/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0329 - accuracy: 0.8402 - val_loss: 0.0596 - val_accuracy: 0.6863\n",
            "Epoch 40/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0329 - accuracy: 0.8362 - val_loss: 0.0585 - val_accuracy: 0.8450\n",
            "Epoch 41/60\n",
            "147/147 [==============================] - 8s 53ms/step - loss: 0.0323 - accuracy: 0.8371 - val_loss: 0.0584 - val_accuracy: 0.8664\n",
            "Epoch 42/60\n",
            "147/147 [==============================] - 7s 50ms/step - loss: 0.0318 - accuracy: 0.8201 - val_loss: 0.0595 - val_accuracy: 0.8023\n",
            "Epoch 43/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0312 - accuracy: 0.7986 - val_loss: 0.0586 - val_accuracy: 0.7393\n",
            "Epoch 44/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0312 - accuracy: 0.7819 - val_loss: 0.0597 - val_accuracy: 0.7918\n",
            "Epoch 45/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0304 - accuracy: 0.7995 - val_loss: 0.0595 - val_accuracy: 0.7103\n",
            "Epoch 46/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0303 - accuracy: 0.7574 - val_loss: 0.0610 - val_accuracy: 0.8485\n",
            "Epoch 47/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0298 - accuracy: 0.7654 - val_loss: 0.0606 - val_accuracy: 0.8253\n",
            "Epoch 48/60\n",
            "147/147 [==============================] - 7s 49ms/step - loss: 0.0293 - accuracy: 0.7536 - val_loss: 0.0622 - val_accuracy: 0.7343\n",
            "Epoch 49/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0293 - accuracy: 0.7505 - val_loss: 0.0623 - val_accuracy: 0.7716\n",
            "Epoch 50/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0283 - accuracy: 0.7575 - val_loss: 0.0621 - val_accuracy: 0.7815\n",
            "Epoch 51/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0281 - accuracy: 0.7449 - val_loss: 0.0617 - val_accuracy: 0.7968\n",
            "Epoch 52/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0275 - accuracy: 0.7578 - val_loss: 0.0629 - val_accuracy: 0.6584\n",
            "Epoch 53/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0280 - accuracy: 0.7546 - val_loss: 0.0649 - val_accuracy: 0.6998\n",
            "Epoch 54/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0273 - accuracy: 0.7133 - val_loss: 0.0652 - val_accuracy: 0.7433\n",
            "Epoch 55/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0264 - accuracy: 0.7243 - val_loss: 0.0645 - val_accuracy: 0.7188\n",
            "Epoch 56/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0262 - accuracy: 0.7295 - val_loss: 0.0636 - val_accuracy: 0.7433\n",
            "Epoch 57/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0258 - accuracy: 0.7194 - val_loss: 0.0667 - val_accuracy: 0.6868\n",
            "Epoch 58/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0255 - accuracy: 0.6978 - val_loss: 0.0651 - val_accuracy: 0.7244\n",
            "Epoch 59/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0255 - accuracy: 0.7140 - val_loss: 0.0663 - val_accuracy: 0.7087\n",
            "Epoch 60/60\n",
            "147/147 [==============================] - 7s 48ms/step - loss: 0.0253 - accuracy: 0.6937 - val_loss: 0.0668 - val_accuracy: 0.5427\n",
            "Training Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_drop.predict(X_test)\n",
        "predictions = (predictions >= .5)\n",
        "accuracy3 = accuracy_score(y_test, predictions)\n",
        "print(\"accuracy: {}\".format(accuracy3))\n",
        "\n",
        "report = analysePredictions(predictions, y_test)\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "  print(\n",
        "  \"\"\"\n",
        "{}:\n",
        "    Count: {}\n",
        "      \n",
        "      -True positive: {}\n",
        "      -False positive: {}\n",
        "      -True negative: {}\n",
        "      -False negative: {} \n",
        "\n",
        "{}\n",
        "  \"\"\".format(label, report[i]['COUNT'], report[i]['TP'], report[i]['FP'], report[i]['TN'], report[i]['FN'], confusion_matrix(y_test[:, i], predictions[:,i]))#On a aussi la possibilité d'utiliser confusion_matrix pour déterminer ces valeurs\n",
        "  )"
      ],
      "metadata": {
        "id": "p7jc4RxzzEy3",
        "outputId": "d2f01117-b0d0-4171-cc2c-fafca048ba0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9111786828838921\n",
            "\n",
            "toxic:\n",
            "    Count: 1234\n",
            "      \n",
            "      -True positive: 760\n",
            "      -False positive: 111\n",
            "      -True negative: 11152\n",
            "      -False negative: 474 \n",
            "\n",
            "[[11152   111]\n",
            " [  474   760]]\n",
            "  \n",
            "\n",
            "severe_toxic:\n",
            "    Count: 130\n",
            "      \n",
            "      -True positive: 27\n",
            "      -False positive: 23\n",
            "      -True negative: 12344\n",
            "      -False negative: 103 \n",
            "\n",
            "[[12344    23]\n",
            " [  103    27]]\n",
            "  \n",
            "\n",
            "obscene:\n",
            "    Count: 637\n",
            "      \n",
            "      -True positive: 435\n",
            "      -False positive: 86\n",
            "      -True negative: 11774\n",
            "      -False negative: 202 \n",
            "\n",
            "[[11774    86]\n",
            " [  202   435]]\n",
            "  \n",
            "\n",
            "threat:\n",
            "    Count: 44\n",
            "      \n",
            "      -True positive: 9\n",
            "      -False positive: 11\n",
            "      -True negative: 12442\n",
            "      -False negative: 35 \n",
            "\n",
            "[[12442    11]\n",
            " [   35     9]]\n",
            "  \n",
            "\n",
            "insult:\n",
            "    Count: 617\n",
            "      \n",
            "      -True positive: 317\n",
            "      -False positive: 106\n",
            "      -True negative: 11774\n",
            "      -False negative: 300 \n",
            "\n",
            "[[11774   106]\n",
            " [  300   317]]\n",
            "  \n",
            "\n",
            "identity_hate:\n",
            "    Count: 108\n",
            "      \n",
            "      -True positive: 26\n",
            "      -False positive: 12\n",
            "      -True negative: 12377\n",
            "      -False negative: 82 \n",
            "\n",
            "[[12377    12]\n",
            " [   82    26]]\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a finalement un modèle un peu plus précis avec environ 91% de précision."
      ],
      "metadata": {
        "id": "5Rma2DGzWxtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyseComments_drop(comments):\n",
        "  if isinstance(comments, str): #La fonction peut prendre en paramètre une simple string \n",
        "    comments = [comments]\n",
        "  sequences = tokenizer.texts_to_sequences(comments)\n",
        "  x = pad_sequences(sequences, truncating=truncating, padding=padding, maxlen=max_length)\n",
        "\n",
        "  predictions = model_drop.predict(x)\n",
        "  predictions = (predictions >= .5)\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for i, pred in enumerate(predictions):\n",
        "    tmp = []\n",
        "    for j, label in enumerate(labels):\n",
        "      if pred[j]:\n",
        "        tmp.append(label)\n",
        "    \n",
        "    if not tmp: #Si aucun label n'est choisi, alors le commentaire est normal\n",
        "      tmp.append('normal')\n",
        "\n",
        "    result.append(tmp)\n",
        "  \n",
        "  return result"
      ],
      "metadata": {
        "id": "RCm68YzpUnHp"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments = [\"Bidirectionnal is shit\", \"Not at all, bidirectionnal and dropout seems great\"]\n",
        "result = analyseComments_drop(comments)\n",
        "for i, comment in enumerate(comments):\n",
        "  print(\"'{}':\".format(comment))\n",
        "  for res in result[i]:\n",
        "    print(\"\\t-{}\".format(res))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "XsNWzC2oWcLo",
        "outputId": "4065b841-496d-431d-95d9-68e565eb8ae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Bidirectionnal is shit':\n",
            "\t-toxic\n",
            "\t-obscene\n",
            "\n",
            "\n",
            "'Not at all, bidirectionnal and dropout seems great':\n",
            "\t-normal\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}